{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b50484d2-bfa4-40b6-82cd-e8bf86187cfd",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (1896117820.py, line 26)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mimport scripts.05_model_inferencing.model_inference\u001b[39m\n                     ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pprint\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StringType, IntegerType, FloatType, DateType\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score, roc_auc_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import model_inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcac9436-de95-4ebf-9655-56df8e1eafd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a .py script that takes a snapshot date, loads a model artefact and make an inference and save to datamart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c91bb1-bcf0-4195-90f3-dc88806ebf8c",
   "metadata": {},
   "source": [
    "## set up pyspark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fb3bc6-4166-4893-88e1-0d3140df5a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SparkSession\n",
    "spark = pyspark.sql.SparkSession.builder \\\n",
    "    .appName(\"dev\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Set log level to ERROR to hide warnings\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30206071-5f00-4c3b-be13-55c54db8e336",
   "metadata": {},
   "source": [
    "## set up config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca7d9f0-cfbc-4098-826c-5537ba56b108",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_date_str = \"2016-05-01\"\n",
    "model_name = \"credit_model_2017_03_01.pkl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f0bb22-745b-4342-9779-4425795dc752",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "config[\"snapshot_date_str\"] = snapshot_date_str\n",
    "config[\"snapshot_date\"] = datetime.strptime(config[\"snapshot_date_str\"], \"%Y-%m-%d\")\n",
    "config[\"model_name\"] = model_name\n",
    "config[\"model_bank_directory\"] = \"/app/notebooks/06_model_training/model_bank/\" \n",
    "config[\"model_artefact_filepath\"] = config[\"model_bank_directory\"] + config[\"model_name\"]\n",
    "\n",
    "pprint.pprint(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea8c974-7a80-44ec-a73f-b72c46b70972",
   "metadata": {},
   "source": [
    "## load model artefact from model bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4704571-1729-49ef-b2fb-e7346fc37d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from the pickle file\n",
    "with open(config[\"model_artefact_filepath\"], 'rb') as file:\n",
    "    model_artefact = pickle.load(file)\n",
    "\n",
    "print(\"Model loaded successfully! \" + config[\"model_artefact_filepath\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441303bb-1736-4589-8537-c914d8d843b1",
   "metadata": {},
   "source": [
    "## load feature store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d002feb1-30f5-415a-91ef-b686ee8de99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_location = \"/app/datamart/gold/inference_feature_store\"\n",
    "\n",
    "specific_feature_file = f\"{feature_location}snapshot_date={config['snapshot_date_str']}/*.parquet\"\n",
    "specific_feature_dir = f\"{feature_location}snapshot_date={config['snapshot_date_str']}/\"\n",
    "\n",
    "print(f\"Looking for feature files in: {specific_feature_dir}\")\n",
    "\n",
    "# Check if the specific partition directory exists and has parquet files\n",
    "parquet_files_exist = False\n",
    "features_sdf = None\n",
    "\n",
    "# Option 1: Check if specific partition exists and load it\n",
    "specific_feature_file = f\"{feature_location}snapshot_date={config['snapshot_date_str']}/*.parquet\"\n",
    "specific_feature_dir = f\"{feature_location}snapshot_date={config['snapshot_date_str']}/\"\n",
    "\n",
    "print(f\"Looking for feature files in: {specific_feature_dir}\")\n",
    "\n",
    "# Check if the specific partition directory exists and has parquet files\n",
    "parquet_files_exist = False\n",
    "features_sdf = None\n",
    "\n",
    "try:\n",
    "    # Check if any parquet files exist in the specific partition\n",
    "    parquet_files = glob.glob(specific_feature_file)\n",
    "    if parquet_files:\n",
    "        print(f\"Found {len(parquet_files)} Parquet file(s) for the specific date\")\n",
    "        features_sdf = spark.read.parquet(specific_feature_dir)\n",
    "        parquet_files_exist = True\n",
    "    else:\n",
    "        print(f\"No Parquet files found in specific partition: {specific_feature_dir}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error checking specific partition: {e}\")\n",
    "\n",
    "# Option 2: If specific partition not found, check entire directory\n",
    "if not parquet_files_exist or features_sdf is None or features_sdf.count() == 0:\n",
    "    print(\"Trying to load from entire feature store directory...\")\n",
    "    try:\n",
    "        # Check if any parquet files exist in the entire feature store\n",
    "        all_parquet_files = glob.glob(f\"{feature_location}*.parquet\") or \\\n",
    "                           glob.glob(f\"{feature_location}*/*.parquet\") or \\\n",
    "                           glob.glob(f\"{feature_location}*/*/*.parquet\")\n",
    "        \n",
    "        if all_parquet_files:\n",
    "            print(f\"Found {len(all_parquet_files)} Parquet file(s) in feature store\")\n",
    "            # Load all data and filter by snapshot_date\n",
    "            features_store_sdf = spark.read.parquet(feature_location)\n",
    "            features_sdf = features_store_sdf.filter((col(\"snapshot_date\") == config[\"snapshot_date_str\"]))\n",
    "        else:\n",
    "            print(\"No Parquet files found in feature store directory\")\n",
    "            raise ValueError(f\"No Parquet files found in {feature_location}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading from feature store: {e}\")\n",
    "        # Final fallback: check if it's a schema issue and try with explicit schema\n",
    "        try:\n",
    "            print(\"Attempting to load with explicit schema...\")\n",
    "            # Define a basic schema based on your expected columns\n",
    "            from pyspark.sql.types import StructType, StructField\n",
    "            # Add your expected schema here based on your feature store\n",
    "            # Example:\n",
    "            # schema = StructType([\n",
    "            #     StructField(\"msno\", StringType(), True),\n",
    "            #     StructField(\"snapshot_date\", StringType(), True),\n",
    "            #     StructField(\"fe_1\", FloatType(), True),\n",
    "            #     # ... add all your feature columns\n",
    "            # ])\n",
    "            # features_store_sdf = spark.read.schema(schema).parquet(feature_location)\n",
    "            \n",
    "            # For now, try without schema but with different options\n",
    "            features_store_sdf = spark.read.option(\"mergeSchema\", \"true\").parquet(feature_location)\n",
    "            features_sdf = features_store_sdf.filter((col(\"snapshot_date\") == config[\"snapshot_date_str\"]))\n",
    "        except Exception as final_error:\n",
    "            raise ValueError(f\"Failed to load features: {final_error}\")\n",
    "\n",
    "# Check if we finally have data\n",
    "if features_sdf is None or features_sdf.count() == 0:\n",
    "    raise ValueError(f\"No features found for snapshot date: {config['snapshot_date_str']}\")\n",
    "\n",
    "print(f\"extracted features_sdf: {features_sdf.count()} rows for snapshot_date: {config['snapshot_date_str']}\")\n",
    "\n",
    "# Show schema for debugging\n",
    "print(\"Feature schema:\")\n",
    "features_sdf.printSchema()\n",
    "\n",
    "# Show a sample of the data\n",
    "print(\"Sample data:\")\n",
    "features_sdf.show(5)\n",
    "\n",
    "# Convert to Pandas for sklearn processing\n",
    "features_pdf = features_sdf.toPandas()\n",
    "print(f\"Converted to Pandas DataFrame with shape: {features_pdf.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f361665-930e-47ec-b312-679ecd40cb2e",
   "metadata": {},
   "source": [
    "## preprocess data for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04410356-646a-41d6-8f1e-8876f0f4f147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 8974\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.37343573,  0.38727197, -1.30102033, ..., -0.63976417,\n",
       "        -0.3378844 ,  0.7008268 ],\n",
       "       [-1.1576494 ,  0.35743607, -0.71008323, ...,  0.70437269,\n",
       "         0.2513317 ,  1.06643414],\n",
       "       [ 2.58915379, -0.4282426 , -1.43122681, ..., -0.09431733,\n",
       "        -1.54577741,  0.04658209],\n",
       "       ...,\n",
       "       [-0.26080821, -1.07468707, -1.48130622, ..., -2.14948311,\n",
       "         1.39048282, -0.91554248],\n",
       "       [ 0.36698062,  0.51656086, -0.68003558, ..., -1.72091773,\n",
       "        -0.87799916, -0.8770575 ],\n",
       "       [ 1.2239622 , -0.3685708 , -0.77017853, ...,  0.85047452,\n",
       "         0.4673776 ,  0.51802313]], shape=(8974, 20))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare X_inference\n",
    "feature_cols = [fe_col for fe_col in features_pdf.columns if fe_col.startswith('fe_')]\n",
    "X_inference = features_pdf[feature_cols]\n",
    "\n",
    "# apply transformer - standard scaler\n",
    "transformer_stdscaler = model_artefact[\"preprocessing_transformers\"][\"stdscaler\"]\n",
    "X_inference = transformer_stdscaler.transform(X_inference)\n",
    "\n",
    "print('X_inference', X_inference.shape[0])\n",
    "X_inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a4362f-9dee-4838-a030-a74b88884b4f",
   "metadata": {},
   "source": [
    "## model prediction inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5e85498-68bb-4083-8035-3247d7e296d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_artefact' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# load model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m model = \u001b[43mmodel_artefact\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# predict model\u001b[39;00m\n\u001b[32m      5\u001b[39m y_inference = model.predict_proba(X_inference)[:, \u001b[32m1\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'model_artefact' is not defined"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model = model_artefact[\"model\"]\n",
    "\n",
    "# predict model\n",
    "y_inference = model.predict_proba(X_inference)[:, 1]\n",
    "\n",
    "# prepare output\n",
    "y_inference_pdf = features_pdf[[\"msno\",\"snapshot_date\"]].copy()\n",
    "y_inference_pdf[\"model_name\"] = config[\"model_name\"]\n",
    "y_inference_pdf[\"model_predictions\"] = y_inference\n",
    "y_inference_pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3fe2b8-4642-486d-aa3b-2d7703ad3d15",
   "metadata": {},
   "source": [
    "## save model inference to datamart gold table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c28e3e5-81ca-4685-a1f1-f1df12908a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datamart/gold/model_predictions/credit_model_2017_03_01/\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_inference_pdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m partition_name = config[\u001b[33m\"\u001b[39m\u001b[33mmodel_name\u001b[39m\u001b[33m\"\u001b[39m][:-\u001b[32m4\u001b[39m] + \u001b[33m\"\u001b[39m\u001b[33m_predictions_\u001b[39m\u001b[33m\"\u001b[39m + snapshot_date_str.replace(\u001b[33m'\u001b[39m\u001b[33m-\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33m_\u001b[39m\u001b[33m'\u001b[39m) + \u001b[33m'\u001b[39m\u001b[33m.parquet\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     10\u001b[39m filepath = gold_directory + partition_name\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m spark.createDataFrame(\u001b[43my_inference_pdf\u001b[49m).write.mode(\u001b[33m\"\u001b[39m\u001b[33moverwrite\u001b[39m\u001b[33m\"\u001b[39m).parquet(filepath)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# df.toPandas().to_parquet(filepath,\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m#           compression='gzip')\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33msaved to:\u001b[39m\u001b[33m'\u001b[39m, filepath)\n",
      "\u001b[31mNameError\u001b[39m: name 'y_inference_pdf' is not defined"
     ]
    }
   ],
   "source": [
    "# create bronze datalake\n",
    "gold_directory = f\"/app/datamart/gold/model_predictions/{config[\"model_name\"][:-4]}/\"\n",
    "print(gold_directory)\n",
    "\n",
    "if not os.path.exists(gold_directory):\n",
    "    os.makedirs(gold_directory)\n",
    "\n",
    "# save gold table - IRL connect to database to write\n",
    "partition_name = config[\"model_name\"][:-4] + \"_predictions_\" + snapshot_date_str.replace('-','_') + '.parquet'\n",
    "filepath = gold_directory + partition_name\n",
    "spark.createDataFrame(y_inference_pdf).write.mode(\"overwrite\").parquet(filepath)\n",
    "# df.toPandas().to_parquet(filepath,\n",
    "#           compression='gzip')\n",
    "print('saved to:', filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a0dfb6-dc32-4a70-9118-9d924213fb2c",
   "metadata": {},
   "source": [
    "## backfill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb286f34-f8fd-4f37-84af-9f8296c10fe5",
   "metadata": {},
   "source": [
    "In the model inference pipeline context, backfill means running inference for historical dates that have been missed when the model was first deployed.\n",
    "\n",
    "Example:\n",
    "\n",
    "MODEL DEPLOYED: March 1, 2024\n",
    "INFERENCE STARTS: March 1, 2024 → Predicts for March 2024 only\n",
    "MISSING: January 2024, February 2024 predictions ❌\n",
    "\n",
    "MODEL DEPLOYED: March 1, 2024  \n",
    "BACKFILL RUN: March 1, 2024 → Generates predictions for:\n",
    "- January 2024 ✅\n",
    "- February 2024 ✅  \n",
    "- March 2024 ✅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4a8f65f-d5d1-45cf-8eaa-bd9c54991a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up config\n",
    "snapshot_date_str = \"2016-05-01\"\n",
    "\n",
    "start_date_str = \"2016-04-01\"\n",
    "end_date_str = \"2016-4-30\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "849e738c-c717-400f-b72d-ba9951866ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate list of dates to process\n",
    "def generate_first_of_month_dates(start_date_str, end_date_str):\n",
    "    # Convert the date strings to datetime objects\n",
    "    start_date = datetime.strptime(start_date_str, \"%Y-%m-%d\")\n",
    "    end_date = datetime.strptime(end_date_str, \"%Y-%m-%d\")\n",
    "    \n",
    "    # List to store the first of month dates\n",
    "    first_of_month_dates = []\n",
    "\n",
    "    # Start from the first of the month of the start_date\n",
    "    current_date = datetime(start_date.year, start_date.month, 1)\n",
    "\n",
    "    while current_date <= end_date:\n",
    "        # Append the date in yyyy-mm-dd format\n",
    "        first_of_month_dates.append(current_date.strftime(\"%Y-%m-%d\"))\n",
    "        \n",
    "        # Move to the first of the next month\n",
    "        if current_date.month == 12:\n",
    "            current_date = datetime(current_date.year + 1, 1, 1)\n",
    "        else:\n",
    "            current_date = datetime(current_date.year, current_date.month + 1, 1)\n",
    "\n",
    "    return first_of_month_dates\n",
    "\n",
    "dates_str_lst = generate_first_of_month_dates(start_date_str, end_date_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93576148-36ca-4571-b327-2317f9656cf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-01\n",
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/credit_model_2024_09_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'credit_model_2024_09_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2023, 1, 1, 0, 0),\n",
      " 'snapshot_date_str': '2023-01-01'}\n",
      "Model loaded successfully! model_bank/credit_model_2024_09_01.pkl\n",
      "extracted features_sdf 8974 2023-01-01 00:00:00\n",
      "X_inference 8974\n",
      "datamart/gold/model_predictions/credit_model_2024_09_01/\n",
      "saved to: datamart/gold/model_predictions/credit_model_2024_09_01/credit_model_2024_09_01_predictions_2023_01_01.parquet\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "2023-02-01\n",
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/credit_model_2024_09_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'credit_model_2024_09_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2023, 2, 1, 0, 0),\n",
      " 'snapshot_date_str': '2023-02-01'}\n",
      "Model loaded successfully! model_bank/credit_model_2024_09_01.pkl\n",
      "extracted features_sdf 8974 2023-02-01 00:00:00\n",
      "X_inference 8974\n",
      "datamart/gold/model_predictions/credit_model_2024_09_01/\n",
      "saved to: datamart/gold/model_predictions/credit_model_2024_09_01/credit_model_2024_09_01_predictions_2023_02_01.parquet\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "2023-03-01\n",
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/credit_model_2024_09_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'credit_model_2024_09_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2023, 3, 1, 0, 0),\n",
      " 'snapshot_date_str': '2023-03-01'}\n",
      "Model loaded successfully! model_bank/credit_model_2024_09_01.pkl\n",
      "extracted features_sdf 8974 2023-03-01 00:00:00\n",
      "X_inference 8974\n",
      "datamart/gold/model_predictions/credit_model_2024_09_01/\n",
      "saved to: datamart/gold/model_predictions/credit_model_2024_09_01/credit_model_2024_09_01_predictions_2023_03_01.parquet\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "2023-04-01\n",
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/credit_model_2024_09_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'credit_model_2024_09_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2023, 4, 1, 0, 0),\n",
      " 'snapshot_date_str': '2023-04-01'}\n",
      "Model loaded successfully! model_bank/credit_model_2024_09_01.pkl\n",
      "extracted features_sdf 8974 2023-04-01 00:00:00\n",
      "X_inference 8974\n",
      "datamart/gold/model_predictions/credit_model_2024_09_01/\n",
      "saved to: datamart/gold/model_predictions/credit_model_2024_09_01/credit_model_2024_09_01_predictions_2023_04_01.parquet\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "2023-05-01\n",
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/credit_model_2024_09_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'credit_model_2024_09_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2023, 5, 1, 0, 0),\n",
      " 'snapshot_date_str': '2023-05-01'}\n",
      "Model loaded successfully! model_bank/credit_model_2024_09_01.pkl\n",
      "extracted features_sdf 8974 2023-05-01 00:00:00\n",
      "X_inference 8974\n",
      "datamart/gold/model_predictions/credit_model_2024_09_01/\n",
      "saved to: datamart/gold/model_predictions/credit_model_2024_09_01/credit_model_2024_09_01_predictions_2023_05_01.parquet\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "2023-06-01\n",
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/credit_model_2024_09_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'credit_model_2024_09_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2023, 6, 1, 0, 0),\n",
      " 'snapshot_date_str': '2023-06-01'}\n",
      "Model loaded successfully! model_bank/credit_model_2024_09_01.pkl\n",
      "extracted features_sdf 8974 2023-06-01 00:00:00\n",
      "X_inference 8974\n",
      "datamart/gold/model_predictions/credit_model_2024_09_01/\n",
      "saved to: datamart/gold/model_predictions/credit_model_2024_09_01/credit_model_2024_09_01_predictions_2023_06_01.parquet\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "2023-07-01\n",
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/credit_model_2024_09_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'credit_model_2024_09_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2023, 7, 1, 0, 0),\n",
      " 'snapshot_date_str': '2023-07-01'}\n",
      "Model loaded successfully! model_bank/credit_model_2024_09_01.pkl\n",
      "extracted features_sdf 8974 2023-07-01 00:00:00\n",
      "X_inference 8974\n",
      "datamart/gold/model_predictions/credit_model_2024_09_01/\n",
      "saved to: datamart/gold/model_predictions/credit_model_2024_09_01/credit_model_2024_09_01_predictions_2023_07_01.parquet\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "2023-08-01\n",
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/credit_model_2024_09_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'credit_model_2024_09_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2023, 8, 1, 0, 0),\n",
      " 'snapshot_date_str': '2023-08-01'}\n",
      "Model loaded successfully! model_bank/credit_model_2024_09_01.pkl\n",
      "extracted features_sdf 8974 2023-08-01 00:00:00\n",
      "X_inference 8974\n",
      "datamart/gold/model_predictions/credit_model_2024_09_01/\n",
      "saved to: datamart/gold/model_predictions/credit_model_2024_09_01/credit_model_2024_09_01_predictions_2023_08_01.parquet\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "2023-09-01\n",
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/credit_model_2024_09_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'credit_model_2024_09_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2023, 9, 1, 0, 0),\n",
      " 'snapshot_date_str': '2023-09-01'}\n",
      "Model loaded successfully! model_bank/credit_model_2024_09_01.pkl\n",
      "extracted features_sdf 8974 2023-09-01 00:00:00\n",
      "X_inference 8974\n",
      "datamart/gold/model_predictions/credit_model_2024_09_01/\n",
      "saved to: datamart/gold/model_predictions/credit_model_2024_09_01/credit_model_2024_09_01_predictions_2023_09_01.parquet\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "2023-10-01\n",
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/credit_model_2024_09_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'credit_model_2024_09_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2023, 10, 1, 0, 0),\n",
      " 'snapshot_date_str': '2023-10-01'}\n",
      "Model loaded successfully! model_bank/credit_model_2024_09_01.pkl\n",
      "extracted features_sdf 8974 2023-10-01 00:00:00\n",
      "X_inference 8974\n",
      "datamart/gold/model_predictions/credit_model_2024_09_01/\n",
      "saved to: datamart/gold/model_predictions/credit_model_2024_09_01/credit_model_2024_09_01_predictions_2023_10_01.parquet\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "2023-11-01\n",
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/credit_model_2024_09_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'credit_model_2024_09_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2023, 11, 1, 0, 0),\n",
      " 'snapshot_date_str': '2023-11-01'}\n",
      "Model loaded successfully! model_bank/credit_model_2024_09_01.pkl\n",
      "extracted features_sdf 8974 2023-11-01 00:00:00\n",
      "X_inference 8974\n",
      "datamart/gold/model_predictions/credit_model_2024_09_01/\n",
      "saved to: datamart/gold/model_predictions/credit_model_2024_09_01/credit_model_2024_09_01_predictions_2023_11_01.parquet\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "2023-12-01\n",
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/credit_model_2024_09_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'credit_model_2024_09_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2023, 12, 1, 0, 0),\n",
      " 'snapshot_date_str': '2023-12-01'}\n",
      "Model loaded successfully! model_bank/credit_model_2024_09_01.pkl\n",
      "extracted features_sdf 8974 2023-12-01 00:00:00\n",
      "X_inference 8974\n",
      "datamart/gold/model_predictions/credit_model_2024_09_01/\n",
      "saved to: datamart/gold/model_predictions/credit_model_2024_09_01/credit_model_2024_09_01_predictions_2023_12_01.parquet\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "2024-01-01\n",
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/credit_model_2024_09_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'credit_model_2024_09_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2024, 1, 1, 0, 0),\n",
      " 'snapshot_date_str': '2024-01-01'}\n",
      "Model loaded successfully! model_bank/credit_model_2024_09_01.pkl\n",
      "extracted features_sdf 8974 2024-01-01 00:00:00\n",
      "X_inference 8974\n",
      "datamart/gold/model_predictions/credit_model_2024_09_01/\n",
      "saved to: datamart/gold/model_predictions/credit_model_2024_09_01/credit_model_2024_09_01_predictions_2024_01_01.parquet\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "2024-02-01\n",
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/credit_model_2024_09_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'credit_model_2024_09_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2024, 2, 1, 0, 0),\n",
      " 'snapshot_date_str': '2024-02-01'}\n",
      "Model loaded successfully! model_bank/credit_model_2024_09_01.pkl\n",
      "extracted features_sdf 8974 2024-02-01 00:00:00\n",
      "X_inference 8974\n",
      "datamart/gold/model_predictions/credit_model_2024_09_01/\n",
      "saved to: datamart/gold/model_predictions/credit_model_2024_09_01/credit_model_2024_09_01_predictions_2024_02_01.parquet\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "2024-03-01\n",
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/credit_model_2024_09_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'credit_model_2024_09_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2024, 3, 1, 0, 0),\n",
      " 'snapshot_date_str': '2024-03-01'}\n",
      "Model loaded successfully! model_bank/credit_model_2024_09_01.pkl\n",
      "extracted features_sdf 8974 2024-03-01 00:00:00\n",
      "X_inference 8974\n",
      "datamart/gold/model_predictions/credit_model_2024_09_01/\n",
      "saved to: datamart/gold/model_predictions/credit_model_2024_09_01/credit_model_2024_09_01_predictions_2024_03_01.parquet\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "2024-04-01\n",
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/credit_model_2024_09_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'credit_model_2024_09_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2024, 4, 1, 0, 0),\n",
      " 'snapshot_date_str': '2024-04-01'}\n",
      "Model loaded successfully! model_bank/credit_model_2024_09_01.pkl\n",
      "extracted features_sdf 8974 2024-04-01 00:00:00\n",
      "X_inference 8974\n",
      "datamart/gold/model_predictions/credit_model_2024_09_01/\n",
      "saved to: datamart/gold/model_predictions/credit_model_2024_09_01/credit_model_2024_09_01_predictions_2024_04_01.parquet\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "2024-05-01\n",
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/credit_model_2024_09_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'credit_model_2024_09_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2024, 5, 1, 0, 0),\n",
      " 'snapshot_date_str': '2024-05-01'}\n",
      "Model loaded successfully! model_bank/credit_model_2024_09_01.pkl\n",
      "extracted features_sdf 8974 2024-05-01 00:00:00\n",
      "X_inference 8974\n",
      "datamart/gold/model_predictions/credit_model_2024_09_01/\n",
      "saved to: datamart/gold/model_predictions/credit_model_2024_09_01/credit_model_2024_09_01_predictions_2024_05_01.parquet\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "2024-06-01\n",
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/credit_model_2024_09_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'credit_model_2024_09_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2024, 6, 1, 0, 0),\n",
      " 'snapshot_date_str': '2024-06-01'}\n",
      "Model loaded successfully! model_bank/credit_model_2024_09_01.pkl\n",
      "extracted features_sdf 8974 2024-06-01 00:00:00\n",
      "X_inference 8974\n",
      "datamart/gold/model_predictions/credit_model_2024_09_01/\n",
      "saved to: datamart/gold/model_predictions/credit_model_2024_09_01/credit_model_2024_09_01_predictions_2024_06_01.parquet\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "2024-07-01\n",
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/credit_model_2024_09_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'credit_model_2024_09_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2024, 7, 1, 0, 0),\n",
      " 'snapshot_date_str': '2024-07-01'}\n",
      "Model loaded successfully! model_bank/credit_model_2024_09_01.pkl\n",
      "extracted features_sdf 8974 2024-07-01 00:00:00\n",
      "X_inference 8974\n",
      "datamart/gold/model_predictions/credit_model_2024_09_01/\n",
      "saved to: datamart/gold/model_predictions/credit_model_2024_09_01/credit_model_2024_09_01_predictions_2024_07_01.parquet\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "2024-08-01\n",
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/credit_model_2024_09_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'credit_model_2024_09_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2024, 8, 1, 0, 0),\n",
      " 'snapshot_date_str': '2024-08-01'}\n",
      "Model loaded successfully! model_bank/credit_model_2024_09_01.pkl\n",
      "extracted features_sdf 8974 2024-08-01 00:00:00\n",
      "X_inference 8974\n",
      "datamart/gold/model_predictions/credit_model_2024_09_01/\n",
      "saved to: datamart/gold/model_predictions/credit_model_2024_09_01/credit_model_2024_09_01_predictions_2024_08_01.parquet\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "2024-09-01\n",
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/credit_model_2024_09_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'credit_model_2024_09_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2024, 9, 1, 0, 0),\n",
      " 'snapshot_date_str': '2024-09-01'}\n",
      "Model loaded successfully! model_bank/credit_model_2024_09_01.pkl\n",
      "extracted features_sdf 8974 2024-09-01 00:00:00\n",
      "X_inference 8974\n",
      "datamart/gold/model_predictions/credit_model_2024_09_01/\n",
      "saved to: datamart/gold/model_predictions/credit_model_2024_09_01/credit_model_2024_09_01_predictions_2024_09_01.parquet\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "2024-10-01\n",
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/credit_model_2024_09_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'credit_model_2024_09_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2024, 10, 1, 0, 0),\n",
      " 'snapshot_date_str': '2024-10-01'}\n",
      "Model loaded successfully! model_bank/credit_model_2024_09_01.pkl\n",
      "extracted features_sdf 8974 2024-10-01 00:00:00\n",
      "X_inference 8974\n",
      "datamart/gold/model_predictions/credit_model_2024_09_01/\n",
      "saved to: datamart/gold/model_predictions/credit_model_2024_09_01/credit_model_2024_09_01_predictions_2024_10_01.parquet\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "2024-11-01\n",
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/credit_model_2024_09_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'credit_model_2024_09_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2024, 11, 1, 0, 0),\n",
      " 'snapshot_date_str': '2024-11-01'}\n",
      "Model loaded successfully! model_bank/credit_model_2024_09_01.pkl\n",
      "extracted features_sdf 8974 2024-11-01 00:00:00\n",
      "X_inference 8974\n",
      "datamart/gold/model_predictions/credit_model_2024_09_01/\n",
      "saved to: datamart/gold/model_predictions/credit_model_2024_09_01/credit_model_2024_09_01_predictions_2024_11_01.parquet\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "2024-12-01\n",
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/credit_model_2024_09_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'credit_model_2024_09_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2024, 12, 1, 0, 0),\n",
      " 'snapshot_date_str': '2024-12-01'}\n",
      "Model loaded successfully! model_bank/credit_model_2024_09_01.pkl\n",
      "extracted features_sdf 8974 2024-12-01 00:00:00\n",
      "X_inference 8974\n",
      "datamart/gold/model_predictions/credit_model_2024_09_01/\n",
      "saved to: datamart/gold/model_predictions/credit_model_2024_09_01/credit_model_2024_09_01_predictions_2024_12_01.parquet\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for snapshot_date in dates_str_lst:\n",
    "    print(snapshot_date)\n",
    "    model_inference.main(snapshot_date, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c339e3cb-1826-49a0-ac73-cb381f85b033",
   "metadata": {},
   "source": [
    "## Check datamart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98ef4abd-3e08-4430-9fc5-d9eb2d0bba5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SparkSession\n",
    "spark = pyspark.sql.SparkSession.builder \\\n",
    "    .appName(\"dev\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Set log level to ERROR to hide warnings\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1dff83cf-fcc1-4a4c-919a-c2c4be859f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row_count: 215376\n",
      "+-----------+-------------+--------------------+-------------------+\n",
      "|Customer_ID|snapshot_date|          model_name|  model_predictions|\n",
      "+-----------+-------------+--------------------+-------------------+\n",
      "| CUS_0x2ff7|   2023-09-01|credit_model_2024...|0.30120009183883667|\n",
      "| CUS_0x303a|   2023-09-01|credit_model_2024...|0.28625059127807617|\n",
      "| CUS_0x305c|   2023-09-01|credit_model_2024...| 0.3428035378456116|\n",
      "| CUS_0x3082|   2023-09-01|credit_model_2024...|0.28813859820365906|\n",
      "| CUS_0x308d|   2023-09-01|credit_model_2024...| 0.3139890134334564|\n",
      "| CUS_0x3101|   2023-09-01|credit_model_2024...|0.22602568566799164|\n",
      "| CUS_0x3127|   2023-09-01|credit_model_2024...| 0.2247123271226883|\n",
      "| CUS_0x3161|   2023-09-01|credit_model_2024...| 0.2053392231464386|\n",
      "| CUS_0x3187|   2023-09-01|credit_model_2024...|0.19738353788852692|\n",
      "| CUS_0x31b8|   2023-09-01|credit_model_2024...|0.39255911111831665|\n",
      "| CUS_0x31c0|   2023-09-01|credit_model_2024...|0.36157599091529846|\n",
      "| CUS_0x3214|   2023-09-01|credit_model_2024...|  0.200511634349823|\n",
      "| CUS_0x323f|   2023-09-01|credit_model_2024...| 0.3125765323638916|\n",
      "| CUS_0x332e|   2023-09-01|credit_model_2024...| 0.3219871520996094|\n",
      "| CUS_0x3389|   2023-09-01|credit_model_2024...| 0.2385900914669037|\n",
      "| CUS_0x33b7|   2023-09-01|credit_model_2024...| 0.1166529655456543|\n",
      "| CUS_0x33cd|   2023-09-01|credit_model_2024...|0.27013838291168213|\n",
      "| CUS_0x33d2|   2023-09-01|credit_model_2024...| 0.4571188986301422|\n",
      "| CUS_0x3410|   2023-09-01|credit_model_2024...| 0.2658039927482605|\n",
      "| CUS_0x35ca|   2023-09-01|credit_model_2024...| 0.3480779528617859|\n",
      "+-----------+-------------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"/app/datamart/gold/model_predictions/credit_model_2017_03_01/\"\n",
    "files_list = [folder_path+os.path.basename(f) for f in glob.glob(os.path.join(folder_path, '*'))]\n",
    "df = spark.read.option(\"header\", \"true\").parquet(*files_list)\n",
    "print(\"row_count:\",df.count())\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418abe90-da75-4c5e-a588-60e00ab3c947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55728897-0715-43a0-904f-5aba101b03aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29fda2c-e869-4ee6-9e98-fc85e69eb136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff19c58-94ad-4abb-984f-b082326c2871",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
