{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e93cd9-5583-4e53-828e-a1ee9c7d70b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026989a7-dc19-48af-bae3-ec61b9ee27d0",
   "metadata": {},
   "source": [
    "## Spark Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df125e7-67f5-4de2-9659-b0d026cb8de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"churn_inference_notebook\")\n",
    "    .master(\"local[*]\")\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"4\")  # faster for local debugging\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "print(\"âœ… Spark started\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9e2fce-88e0-4372-bf9f-79f3533fa4a6",
   "metadata": {},
   "source": [
    "## Load features from feature store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447aed2e-8344-4206-a832-0e8cf1222bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features(spark, snapshot_date_str):\n",
    "    \"\"\"Load inference features for a given snapshot date.\"\"\"\n",
    "    snapshot_date = datetime.strptime(snapshot_date_str, \"%Y-%m-%d\").date()\n",
    "\n",
    "    path = \"/app/datamart/gold/inference_feature_store/\"\n",
    "    print(f\"ðŸ“‚ Loading feature store: {path}\")\n",
    "\n",
    "    df = (\n",
    "        spark.read.parquet(path)\n",
    "        .filter(F.col(\"snapshot_date\") == F.lit(snapshot_date))\n",
    "    )\n",
    "\n",
    "    print(f\"âœ… Loaded features: {df.count()} rows for snapshot_date={snapshot_date}\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e33ac0-dfdb-402b-a553-425c6d16f701",
   "metadata": {},
   "source": [
    "## Load MLflow Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af06bdc1-820c-4d7d-acec-e9fb43301a78",
   "metadata": {},
   "source": [
    "def load_mlflow_model(model_name):\n",
    "    \"\"\"\n",
    "    Load an MLflow model by registered name or full URI.\n",
    "    \"\"\"\n",
    "    mlflow.set_tracking_uri(\"http://mlflow:5000\")\n",
    "\n",
    "    if model_name.startswith(\"models:/\"):\n",
    "        model_uri = model_name\n",
    "    else:\n",
    "        model_uri = f\"models:/{model_name}/Production\"\n",
    "\n",
    "    logger.info(f\"Loading MLflow model from: {model_uri}\")\n",
    "\n",
    "    try:\n",
    "        model = mlflow.sklearn.load_model(model_uri)\n",
    "        logger.info(\"âœ… MLflow model loaded successfully\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load MLflow model: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41611873-8866-451d-89ed-e56cda02f499",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mlflow_model(model_name_or_uri):\n",
    "    \"\"\"Load MLflow model by registered name or full model URI.\"\"\"\n",
    "    \n",
    "    print(f\"ðŸ“¦ Loading MLflow model: {model_name_or_uri}\")\n",
    "\n",
    "    # model = mlflow.pyfunc.load_model(model_name_or_uri)\n",
    "    model = mlflow.sklearn.load_model(model_uri)\n",
    "\n",
    "    print(\"âœ… Model loaded successfully!\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18f58d4-248e-4f4b-8b47-0044dae51c0e",
   "metadata": {},
   "source": [
    "## Save predictions to datamart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c247a653-b9a1-416e-bbf1-84c06d46c5b5",
   "metadata": {},
   "source": [
    "def save_predictions(spark, df_predictions, model_name, snapshot_date_str):\n",
    "    \"\"\"\n",
    "    Save predictions to parquet under:\n",
    "    datamart/gold/model_predictions/<model_name>/\n",
    "    \"\"\"\n",
    "    base_dir = f\"datamart/gold/model_predictions/{model_name}/\"\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "    filename = f\"{model_name}_predictions_{snapshot_date_str.replace('-', '_')}.parquet\"\n",
    "    filepath = os.path.join(base_dir, filename)\n",
    "\n",
    "    (\n",
    "        spark.createDataFrame(df_predictions)\n",
    "            .write.mode(\"overwrite\")\n",
    "            .parquet(filepath)\n",
    "    )\n",
    "\n",
    "    logger.info(f\"âœ… Predictions saved: {filepath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65c4b83-5551-4a23-90fe-6dbdebef514f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions(spark, predictions_pdf, model_name, snapshot_date_str):\n",
    "    \"\"\"Save inference prediction results to parquet.\"\"\"\n",
    "    \n",
    "    output_dir = \"/app/datamart/gold/inference_output/\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    output_path = os.path.join(\n",
    "        output_dir,\n",
    "        f\"{model_name}_predictions_{snapshot_date_str.replace('-', '')}.parquet\"\n",
    "    )\n",
    "\n",
    "    # Convert pandas â†’ spark\n",
    "    preds_sdf = spark.createDataFrame(predictions_pdf)\n",
    "\n",
    "    preds_sdf.write.mode(\"overwrite\").parquet(output_path)\n",
    "\n",
    "    print(f\"âœ… Predictions saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fd4fc0-a81b-49a0-b9c5-0c3345a74ac2",
   "metadata": {},
   "source": [
    "## Main Inference Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7726d8a-466a-4134-80ef-25dd674cdb87",
   "metadata": {},
   "source": [
    "def main(snapshot_date_str, model_name):\n",
    "\n",
    "    logger.info(\"=== Starting Model Inference Job ===\")\n",
    "\n",
    "    # Spark session\n",
    "    spark = pyspark.sql.SparkSession.builder \\\n",
    "        .appName(\"inference\") \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .getOrCreate()\n",
    "    spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "    # Load features\n",
    "    features_sdf = load_features(spark, snapshot_date_str)\n",
    "\n",
    "    logger.info(\"Feature schema:\")\n",
    "    features_sdf.printSchema()\n",
    "\n",
    "    # Convert to pandas\n",
    "    features_pdf = features_sdf.toPandas()\n",
    "    logger.info(f\"Converted Spark â†’ Pandas: shape={features_pdf.shape}\")\n",
    "\n",
    "    # Extract feature columns\n",
    "    # feature_cols = [c for c in features_pdf.columns if c.startswith(\"fe_\")]\n",
    "    feature_cols = ['tenure_days_at_snapshot', 'registered_via', 'city_clean', \n",
    "                'sum_secs_w30', 'active_days_w30', 'complete_rate_w30', \n",
    "                'sum_secs_w7', 'engagement_ratio_7_30', 'days_since_last_play', \n",
    "                'trend_secs_w30', 'auto_renew_share', 'last_is_auto_renew']\n",
    "    X_inference = features_pdf[feature_cols]\n",
    "\n",
    "    # Load MLflow model\n",
    "    model = load_mlflow_model(model_name)\n",
    "\n",
    "    # Predict\n",
    "    y_proba = model.predict_proba(X_inference)[:, 1]\n",
    "\n",
    "    # Output dataframe\n",
    "    output = features_pdf[[\"msno\", \"snapshot_date\"]].copy()\n",
    "    output[\"model_name\"] = model_name\n",
    "    output[\"model_predictions\"] = y_proba\n",
    "\n",
    "    # Save\n",
    "    save_predictions(spark, output, model_name, snapshot_date_str)\n",
    "\n",
    "    spark.stop()\n",
    "    logger.info(\"=== Inference Job Completed ===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36b7358-5723-4208-bf5e-2981b6f6bf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(snapshot_date_str, model_uri):\n",
    "    \"\"\"\n",
    "    Full inference pipeline:\n",
    "    - load features\n",
    "    - convert to pandas\n",
    "    - load MLflow model\n",
    "    - predict_proba\n",
    "    - save output parquet\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Load features ---\n",
    "    features_sdf = load_features(spark, snapshot_date_str)\n",
    "\n",
    "    # Convert to pandas for ML model\n",
    "    features_pdf = features_sdf.toPandas()\n",
    "\n",
    "    # Identify feature columns (assuming fe_ prefix)\n",
    "    # feature_cols = [c for c in features_pdf.columns if c.startswith(\"fe_\")]\n",
    "    feature_cols = ['tenure_days_at_snapshot',\n",
    "                'registered_via',\n",
    "                'city_clean', \n",
    "                'sum_secs_w30',\n",
    "                'active_days_w30',\n",
    "                'complete_rate_w30',\n",
    "                'sum_secs_w7',\n",
    "                'engagement_ratio_7_30',\n",
    "                'days_since_last_play',\n",
    "                'trend_secs_w30',\n",
    "                'auto_renew_share',\n",
    "                'last_is_auto_renew']\n",
    "    X = features_pdf[feature_cols]\n",
    "\n",
    "    # --- Load MLflow model ---\n",
    "    model = load_mlflow_model(model_uri)\n",
    "\n",
    "    # --- Inference ---\n",
    "    preds = model.predict(X)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        proba = model.predict_proba(X)[:, 1]\n",
    "    else:\n",
    "        proba = preds  # fallback for regressors / non-proba models\n",
    "\n",
    "    # --- Build output dataframe ---\n",
    "    output = features_pdf[[\"msno\", \"snapshot_date\"]].copy()\n",
    "    output[\"model_name\"] = model_uri\n",
    "    output[\"prediction\"] = preds\n",
    "    output[\"probability\"] = proba\n",
    "\n",
    "    # --- Save to parquet ---\n",
    "    save_predictions(spark, output, model_uri.replace(\"/\", \"_\"), snapshot_date_str)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53bf93b-ea95-4c5e-b1ef-178a27b250df",
   "metadata": {},
   "source": [
    "## Entry Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99560b6f-0896-4ea3-99cd-18548694d8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_date = \"2016-05-01\"\n",
    "\n",
    "# Choose model from MLflow registry\n",
    "model_uri = \"models:/LogisticRegression/1\"   # or /XGBoost/1, /RandomForest/1\n",
    "\n",
    "results = run_inference(snapshot_date, model_uri)\n",
    "results.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
