{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68e93cd9-5583-4e53-828e-a1ee9c7d70b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026989a7-dc19-48af-bae3-ec61b9ee27d0",
   "metadata": {},
   "source": [
    "## Spark Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7df125e7-67f5-4de2-9659-b0d026cb8de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/05 02:31:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Spark started\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"churn_inference_notebook\")\n",
    "    .master(\"local[*]\")\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"4\")  # faster for local debugging\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "print(\"âœ… Spark started\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9e2fce-88e0-4372-bf9f-79f3533fa4a6",
   "metadata": {},
   "source": [
    "## Load features from feature store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "447aed2e-8344-4206-a832-0e8cf1222bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features(spark, snapshot_date_str):\n",
    "    \"\"\"Load inference features for a given snapshot date.\"\"\"\n",
    "    snapshot_date = datetime.strptime(snapshot_date_str, \"%Y-%m-%d\").date()\n",
    "\n",
    "    path = \"/app/datamart/gold/feature_store/\"\n",
    "    print(f\"ðŸ“‚ Loading feature store: {path}\")\n",
    "\n",
    "    df = (\n",
    "        spark.read.parquet(path)\n",
    "        .filter(F.col(\"snapshot_date\") == F.lit(snapshot_date))\n",
    "    )\n",
    "\n",
    "    print(f\"âœ… Loaded features: {df.count()} rows for snapshot_date={snapshot_date}\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e33ac0-dfdb-402b-a553-425c6d16f701",
   "metadata": {},
   "source": [
    "## Load MLflow Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af06bdc1-820c-4d7d-acec-e9fb43301a78",
   "metadata": {},
   "source": [
    "def load_mlflow_model(model_name):\n",
    "    \"\"\"\n",
    "    Load an MLflow model by registered name or full URI.\n",
    "    \"\"\"\n",
    "    mlflow.set_tracking_uri(\"http://mlflow:5000\")\n",
    "\n",
    "    if model_name.startswith(\"models:/\"):\n",
    "        model_uri = model_name\n",
    "    else:\n",
    "        model_uri = f\"models:/{model_name}/Production\"\n",
    "\n",
    "    logger.info(f\"Loading MLflow model from: {model_uri}\")\n",
    "\n",
    "    try:\n",
    "        model = mlflow.sklearn.load_model(model_uri)\n",
    "        logger.info(\"âœ… MLflow model loaded successfully\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load MLflow model: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41611873-8866-451d-89ed-e56cda02f499",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/05 02:31:40 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "def load_mlflow_model(model_name_or_uri):\n",
    "    \"\"\"Load MLflow model by registered name or full model URI.\"\"\"\n",
    "    \n",
    "    print(f\"ðŸ“¦ Loading MLflow model: {model_name_or_uri}\")\n",
    "\n",
    "    # model = mlflow.pyfunc.load_model(model_name_or_uri)\n",
    "    model = mlflow.sklearn.load_model(model_uri)\n",
    "\n",
    "    print(\"âœ… Model loaded successfully!\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18f58d4-248e-4f4b-8b47-0044dae51c0e",
   "metadata": {},
   "source": [
    "## Save predictions to datamart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c247a653-b9a1-416e-bbf1-84c06d46c5b5",
   "metadata": {},
   "source": [
    "def save_predictions(spark, df_predictions, model_name, snapshot_date_str):\n",
    "    \"\"\"\n",
    "    Save predictions to parquet under:\n",
    "    datamart/gold/model_predictions/<model_name>/\n",
    "    \"\"\"\n",
    "    base_dir = f\"datamart/gold/model_predictions/{model_name}/\"\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "    filename = f\"{model_name}_predictions_{snapshot_date_str.replace('-', '_')}.parquet\"\n",
    "    filepath = os.path.join(base_dir, filename)\n",
    "\n",
    "    (\n",
    "        spark.createDataFrame(df_predictions)\n",
    "            .write.mode(\"overwrite\")\n",
    "            .parquet(filepath)\n",
    "    )\n",
    "\n",
    "    logger.info(f\"âœ… Predictions saved: {filepath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d65c4b83-5551-4a23-90fe-6dbdebef514f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions(spark, predictions_pdf, model_name, snapshot_date_str):\n",
    "    \"\"\"Save inference prediction results to parquet.\"\"\"\n",
    "    \n",
    "    output_dir = \"/app/datamart/gold/inference_output/\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    output_path = os.path.join(\n",
    "        output_dir,\n",
    "        f\"{model_name}_predictions_{snapshot_date_str.replace('-', '')}.parquet\"\n",
    "    )\n",
    "\n",
    "    # Convert pandas â†’ spark\n",
    "    preds_sdf = spark.createDataFrame(predictions_pdf)\n",
    "\n",
    "    preds_sdf.write.mode(\"overwrite\").parquet(output_path)\n",
    "\n",
    "    print(f\"âœ… Predictions saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fd4fc0-a81b-49a0-b9c5-0c3345a74ac2",
   "metadata": {},
   "source": [
    "## Main Inference Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7726d8a-466a-4134-80ef-25dd674cdb87",
   "metadata": {},
   "source": [
    "def main(snapshot_date_str, model_name):\n",
    "\n",
    "    logger.info(\"=== Starting Model Inference Job ===\")\n",
    "\n",
    "    # Spark session\n",
    "    spark = pyspark.sql.SparkSession.builder \\\n",
    "        .appName(\"inference\") \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .getOrCreate()\n",
    "    spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "    # Load features\n",
    "    features_sdf = load_features(spark, snapshot_date_str)\n",
    "\n",
    "    logger.info(\"Feature schema:\")\n",
    "    features_sdf.printSchema()\n",
    "\n",
    "    # Convert to pandas\n",
    "    features_pdf = features_sdf.toPandas()\n",
    "    logger.info(f\"Converted Spark â†’ Pandas: shape={features_pdf.shape}\")\n",
    "\n",
    "    # Extract feature columns\n",
    "    # feature_cols = [c for c in features_pdf.columns if c.startswith(\"fe_\")]\n",
    "    feature_cols = ['tenure_days_at_snapshot', 'registered_via', 'city_clean', \n",
    "                'sum_secs_w30', 'active_days_w30', 'complete_rate_w30', \n",
    "                'sum_secs_w7', 'engagement_ratio_7_30', 'days_since_last_play', \n",
    "                'trend_secs_w30', 'auto_renew_share', 'last_is_auto_renew']\n",
    "    X_inference = features_pdf[feature_cols]\n",
    "\n",
    "    # Load MLflow model\n",
    "    model = load_mlflow_model(model_name)\n",
    "\n",
    "    # Predict\n",
    "    y_proba = model.predict_proba(X_inference)[:, 1]\n",
    "\n",
    "    # Output dataframe\n",
    "    output = features_pdf[[\"msno\", \"snapshot_date\"]].copy()\n",
    "    output[\"model_name\"] = model_name\n",
    "    output[\"model_predictions\"] = y_proba\n",
    "\n",
    "    # Save\n",
    "    save_predictions(spark, output, model_name, snapshot_date_str)\n",
    "\n",
    "    spark.stop()\n",
    "    logger.info(\"=== Inference Job Completed ===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f36b7358-5723-4208-bf5e-2981b6f6bf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(snapshot_date_str, model_uri):\n",
    "    \"\"\"\n",
    "    Full inference pipeline:\n",
    "    - load features\n",
    "    - convert to pandas\n",
    "    - load MLflow model\n",
    "    - predict_proba\n",
    "    - save output parquet\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Load features ---\n",
    "    features_sdf = load_features(spark, snapshot_date_str)\n",
    "\n",
    "    # Convert to pandas for ML model\n",
    "    features_pdf = features_sdf.toPandas()\n",
    "\n",
    "    # Identify feature columns (assuming fe_ prefix)\n",
    "    # feature_cols = [c for c in features_pdf.columns if c.startswith(\"fe_\")]\n",
    "    feature_cols = ['tenure_days_at_snapshot',\n",
    "                'registered_via',\n",
    "                'city_clean', \n",
    "                'sum_secs_w30',\n",
    "                'active_days_w30',\n",
    "                'complete_rate_w30',\n",
    "                'sum_secs_w7',\n",
    "                'engagement_ratio_7_30',\n",
    "                'days_since_last_play',\n",
    "                'trend_secs_w30',\n",
    "                'auto_renew_share',\n",
    "                'last_is_auto_renew']\n",
    "    X = features_pdf[feature_cols]\n",
    "\n",
    "    # --- Load MLflow model ---\n",
    "    model = load_mlflow_model(model_uri)\n",
    "\n",
    "    # --- Inference ---\n",
    "    preds = model.predict(X)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        proba = model.predict_proba(X)[:, 1]\n",
    "    else:\n",
    "        proba = preds  # fallback for regressors / non-proba models\n",
    "\n",
    "    # --- Build output dataframe ---\n",
    "    output = features_pdf[[\"msno\", \"snapshot_date\"]].copy()\n",
    "    output[\"model_name\"] = model_uri\n",
    "    output[\"prediction\"] = preds\n",
    "    output[\"probability\"] = proba\n",
    "\n",
    "    # --- Save to parquet ---\n",
    "    save_predictions(spark, output, model_uri.replace(\"/\", \"_\"), snapshot_date_str)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a1c445-e163-4157-b903-bd6b8101fc28",
   "metadata": {},
   "source": [
    "## Data Preparation: Handle Missing Values & Encoding\n",
    "\n",
    "**Strategy**:\n",
    "1. Create missing value indicators\n",
    "2. Fill missing values with 0\n",
    "3. One-hot encode for Logistic Regression (with scaling)\n",
    "4. Keep original encoding for tree-based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3be22d1-26c9-40dd-bfb0-ae3106a4a544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: ['registered_via', 'city_clean']\n",
      "Numerical columns: ['tenure_days_at_snapshot', 'sum_secs_w30', 'active_days_w30', 'complete_rate_w30', 'sum_secs_w7', 'engagement_ratio_7_30', 'days_since_last_play', 'trend_secs_w30', 'auto_renew_share', 'last_is_auto_renew']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = ['registered_via', 'city_clean']\n",
    "numerical_cols = [col for col in feature_cols if col not in categorical_cols]\n",
    "\n",
    "# Define feature groups for missing indicators\n",
    "activity_features = ['sum_secs_w30', 'active_days_w30', 'complete_rate_w30', \n",
    "                     'sum_secs_w7', 'engagement_ratio_7_30', 'days_since_last_play', \n",
    "                     'trend_secs_w30']\n",
    "demo_features = ['tenure_days_at_snapshot', 'registered_via', 'city_clean']\n",
    "\n",
    "print(f\"Categorical columns: {categorical_cols}\")\n",
    "print(f\"Numerical columns: {numerical_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936c35fb-f686-415f-9ccc-21bc604eec8f",
   "metadata": {},
   "source": [
    "### Step 1: Create Missing Value Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e6a98ce-91b6-4025-b8a9-cd5a8e1e10ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STEP 1] Creating missing value indicator features...\n",
      "  âœ“ Created 'is_missing_activity' indicator\n",
      "  âœ“ Created 'is_missing_demo' indicator\n",
      "  Train - Missing activity: 268,550 (18.8%)\n",
      "  Train - Missing demo: 140,268 (9.8%)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[STEP 1] Creating missing value indicator features...\")\n",
    "\n",
    "# Create indicator features for ALL splits\n",
    "for df in [X_train, X_val, X_test, X_oot]:\n",
    "    # Indicator for missing activity features\n",
    "    df['is_missing_activity'] = df['sum_secs_w30'].isnull().astype(int)\n",
    "    \n",
    "    # Indicator for missing demographic features\n",
    "    df['is_missing_demo'] = df['tenure_days_at_snapshot'].isnull().astype(int)\n",
    "\n",
    "print(f\"  âœ“ Created 'is_missing_activity' indicator\")\n",
    "print(f\"  âœ“ Created 'is_missing_demo' indicator\")\n",
    "print(f\"  Train - Missing activity: {X_train['is_missing_activity'].sum():,} ({X_train['is_missing_activity'].mean():.1%})\")\n",
    "print(f\"  Train - Missing demo: {X_train['is_missing_demo'].sum():,} ({X_train['is_missing_demo'].mean():.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe71cab-bc9b-4645-a618-9d7eaccb134b",
   "metadata": {},
   "source": [
    "### Step 2: Fill Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c6dc84e-ee5f-41fc-beda-b5e2fcf5c5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STEP 2] Filling missing values with 0...\n",
      "  âœ“ All missing values filled with 0\n",
      "  Train missing values: 0\n",
      "  Val missing values: 0\n",
      "  Test missing values: 0\n",
      "  OOT missing values: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[STEP 2] Filling missing values with 0...\")\n",
    "\n",
    "# Fill missing values with 0 (after creating indicators)\n",
    "for df in [X_train, X_val, X_test, X_oot]:\n",
    "    df.fillna(0, inplace=True)\n",
    "\n",
    "print(\"  âœ“ All missing values filled with 0\")\n",
    "\n",
    "# Verify no missing values remain\n",
    "print(f\"  Train missing values: {X_train.isnull().sum().sum()}\")\n",
    "print(f\"  Val missing values: {X_val.isnull().sum().sum()}\")\n",
    "print(f\"  Test missing values: {X_test.isnull().sum().sum()}\")\n",
    "print(f\"  OOT missing values: {X_oot.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e9f55d-ad6e-429a-a693-0fdc3a5f2064",
   "metadata": {},
   "source": [
    "### Step 3: Prepare Data for Logistic Regression (One-Hot Encoding + Scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f8bf836-3989-4808-bee0-08d616857bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STEP 3] One-hot encoding categorical features for Logistic Regression...\n",
      "  âœ“ One-hot encoded 'registered_via' and 'city_clean'\n",
      "  âœ“ Total features after encoding: 37\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[STEP 3] One-hot encoding categorical features for Logistic Regression...\")\n",
    "\n",
    "# Get dummies for registered_via and city_clean\n",
    "X_train_lr = pd.get_dummies(X_train, columns=['registered_via', 'city_clean'], \n",
    "                             drop_first=True, dtype=int)\n",
    "X_val_lr = pd.get_dummies(X_val, columns=['registered_via', 'city_clean'], \n",
    "                           drop_first=True, dtype=int)\n",
    "X_test_lr = pd.get_dummies(X_test, columns=['registered_via', 'city_clean'], \n",
    "                            drop_first=True, dtype=int)\n",
    "X_oot_lr = pd.get_dummies(X_oot, columns=['registered_via', 'city_clean'], \n",
    "                           drop_first=True, dtype=int)\n",
    "\n",
    "# Align columns across all datasets (handle unseen categories)\n",
    "all_columns = X_train_lr.columns\n",
    "for df in [X_val_lr, X_test_lr, X_oot_lr]:\n",
    "    # Add missing columns\n",
    "    for col in all_columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0\n",
    "\n",
    "# Reassign to ensure column alignment\n",
    "X_val_lr = X_val_lr[all_columns]\n",
    "X_test_lr = X_test_lr[all_columns]\n",
    "X_oot_lr = X_oot_lr[all_columns]\n",
    "\n",
    "print(f\"  âœ“ One-hot encoded 'registered_via' and 'city_clean'\")\n",
    "print(f\"  âœ“ Total features after encoding: {X_train_lr.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabbc4f1-b5ae-4599-8ede-bddbc3d4a9ca",
   "metadata": {},
   "source": [
    "### Step 4: Feature Scaling for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4464f74-091a-4353-b706-15a3c74c8f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STEP 4] Scaling numeric features with StandardScaler...\n",
      "  Scaling 9 numeric features: ['tenure_days_at_snapshot', 'sum_secs_w30', 'active_days_w30', 'complete_rate_w30', 'sum_secs_w7', 'engagement_ratio_7_30', 'days_since_last_play', 'trend_secs_w30', 'auto_renew_share']\n",
      "  âœ“ Features scaled (mean=0, std=1)\n",
      "  âœ“ Logistic Regression data ready: (1430517, 37)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[STEP 4] Scaling numeric features with StandardScaler...\")\n",
    "\n",
    "# Identify numeric columns (exclude one-hot encoded columns and binary indicators)\n",
    "numeric_cols = [col for col in X_train_lr.columns \n",
    "                if not col.startswith('registered_via_') \n",
    "                and not col.startswith('city_clean_')\n",
    "                and col not in ['is_missing_activity', 'is_missing_demo', 'last_is_auto_renew']]\n",
    "\n",
    "print(f\"  Scaling {len(numeric_cols)} numeric features: {numeric_cols}\")\n",
    "\n",
    "# Initialize scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training data only\n",
    "X_train_lr[numeric_cols] = scaler.fit_transform(X_train_lr[numeric_cols])\n",
    "\n",
    "# Transform validation, test, and OOT using the same scaler\n",
    "X_val_lr[numeric_cols] = scaler.transform(X_val_lr[numeric_cols])\n",
    "X_test_lr[numeric_cols] = scaler.transform(X_test_lr[numeric_cols])\n",
    "X_oot_lr[numeric_cols] = scaler.transform(X_oot_lr[numeric_cols])\n",
    "\n",
    "print(\"  âœ“ Features scaled (mean=0, std=1)\")\n",
    "print(f\"  âœ“ Logistic Regression data ready: {X_train_lr.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0b7ec2-8059-4be9-b956-40533d32877d",
   "metadata": {},
   "source": [
    "### Step 5: Prepare Data for Tree-Based Models (Original Encoding, No Scaling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dceaabd-8d54-48a1-a856-45cdba227553",
   "metadata": {},
   "source": [
    "print(\"\\n[STEP 5] Preparing data for tree-based models (XGBoost, Random Forest)...\")\n",
    "\n",
    "# For tree-based models, use the data after missing value handling but before one-hot encoding\n",
    "# Tree models can handle label-encoded categoricals and don't need scaling\n",
    "X_train_tree = X_train.copy()\n",
    "X_val_tree = X_val.copy()\n",
    "X_test_tree = X_test.copy()\n",
    "X_oot_tree = X_oot.copy()\n",
    "\n",
    "# Ensure categorical columns are integer type (safe now after fillna)\n",
    "for col in categorical_cols:\n",
    "    X_train_tree[col] = X_train_tree[col].astype(int)\n",
    "    X_val_tree[col] = X_val_tree[col].astype(int)\n",
    "    X_test_tree[col] = X_test_tree[col].astype(int)\n",
    "    X_oot_tree[col] = X_oot_tree[col].astype(int)\n",
    "\n",
    "print(f\"  âœ“ Tree-based model data ready: {X_train_tree.shape}\")\n",
    "print(f\"  âœ“ No scaling applied (tree models don't need it)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53bf93b-ea95-4c5e-b1ef-178a27b250df",
   "metadata": {},
   "source": [
    "## Entry Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99560b6f-0896-4ea3-99cd-18548694d8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Loading feature store: /app/datamart/gold/feature_store/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded features: 26864 rows for snapshot_date=2016-05-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Loading MLflow model: models:/LogisticRegression/1\n",
      "âœ… Model loaded successfully!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- city_clean\n- registered_via\nFeature names seen at fit time, yet now missing:\n- city_clean_1.0\n- city_clean_10.0\n- city_clean_11.0\n- city_clean_12.0\n- city_clean_13.0\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Choose model from MLflow registry\u001b[39;00m\n\u001b[32m      4\u001b[39m model_uri = \u001b[33m\"\u001b[39m\u001b[33mmodels:/LogisticRegression/1\u001b[39m\u001b[33m\"\u001b[39m   \u001b[38;5;66;03m# or /XGBoost/1, /RandomForest/1\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m results = \u001b[43mrun_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msnapshot_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m results.head()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mrun_inference\u001b[39m\u001b[34m(snapshot_date_str, model_uri)\u001b[39m\n\u001b[32m     34\u001b[39m model = load_mlflow_model(model_uri)\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# --- Inference ---\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m preds = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[33m\"\u001b[39m\u001b[33mpredict_proba\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     39\u001b[39m     proba = model.predict_proba(X)[:, \u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/sklearn/linear_model/_base.py:374\u001b[39m, in \u001b[36mLinearClassifierMixin.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    360\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    361\u001b[39m \u001b[33;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[32m    362\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    371\u001b[39m \u001b[33;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[32m    372\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    373\u001b[39m xp, _ = get_namespace(X)\n\u001b[32m--> \u001b[39m\u001b[32m374\u001b[39m scores = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores.shape) == \u001b[32m1\u001b[39m:\n\u001b[32m    376\u001b[39m     indices = xp.astype(scores > \u001b[32m0\u001b[39m, indexing_dtype(xp))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/sklearn/linear_model/_base.py:351\u001b[39m, in \u001b[36mLinearClassifierMixin.decision_function\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    348\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    349\u001b[39m xp, _ = get_namespace(X)\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    352\u001b[39m scores = safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m.coef_.T, dense_output=\u001b[38;5;28;01mTrue\u001b[39;00m) + \u001b[38;5;28mself\u001b[39m.intercept_\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m    354\u001b[39m     xp.reshape(scores, (-\u001b[32m1\u001b[39m,))\n\u001b[32m    355\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (scores.ndim > \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m scores.shape[\u001b[32m1\u001b[39m] == \u001b[32m1\u001b[39m)\n\u001b[32m    356\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m scores\n\u001b[32m    357\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2919\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2835\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvalidate_data\u001b[39m(\n\u001b[32m   2836\u001b[39m     _estimator,\n\u001b[32m   2837\u001b[39m     /,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2843\u001b[39m     **check_params,\n\u001b[32m   2844\u001b[39m ):\n\u001b[32m   2845\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Validate input data and set or check feature names and counts of the input.\u001b[39;00m\n\u001b[32m   2846\u001b[39m \n\u001b[32m   2847\u001b[39m \u001b[33;03m    This helper function should be used in an estimator that requires input\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2917\u001b[39m \u001b[33;03m        validated.\u001b[39;00m\n\u001b[32m   2918\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2919\u001b[39m     \u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2920\u001b[39m     tags = get_tags(_estimator)\n\u001b[32m   2921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tags.target_tags.required:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2777\u001b[39m, in \u001b[36m_check_feature_names\u001b[39m\u001b[34m(estimator, X, reset)\u001b[39m\n\u001b[32m   2774\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[32m   2775\u001b[39m     message += \u001b[33m\"\u001b[39m\u001b[33mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m2777\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[31mValueError\u001b[39m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- city_clean\n- registered_via\nFeature names seen at fit time, yet now missing:\n- city_clean_1.0\n- city_clean_10.0\n- city_clean_11.0\n- city_clean_12.0\n- city_clean_13.0\n- ...\n"
     ]
    }
   ],
   "source": [
    "snapshot_date = \"2016-05-01\"\n",
    "\n",
    "# Choose model from MLflow registry\n",
    "model_uri = \"models:/LogisticRegression/1\"   # or /XGBoost/1, /RandomForest/1\n",
    "\n",
    "results = run_inference(snapshot_date, model_uri)\n",
    "results.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
