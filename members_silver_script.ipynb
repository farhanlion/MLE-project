{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eace65b3-a2c0-4953-af5d-7c9a6034eeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pprint\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StringType, IntegerType, FloatType, DateType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99a2f38d-4122-4c57-96e6-c26936c572eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/10/29 13:22:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Initialize SparkSession\n",
    "spark = pyspark.sql.SparkSession.builder \\\n",
    "    .appName(\"dev\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Set log level to ERROR to hide warnings\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1acb891d-8aec-402a-94b3-96750ebd7bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = (spark.read\n",
    "      .option(\"header\", True)\n",
    "      .option(\"inferSchema\", True)\n",
    "      .parquet(\"datamart/bronze/user_logs/year=2015/month=01\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "492a8457-5187-4224-b68f-90454cac7dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_members = (spark.read\n",
    "      .option(\"header\", True)\n",
    "      .option(\"inferSchema\", True)\n",
    "      .parquet(\"datamart/bronze/members\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7444bf97-56ef-40fa-aae7-6852c3111556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= 0) Setup =========\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "SNAPSHOT_DATE_STR = \"2017-02-28\"   # cutoff cho train\n",
    "SNAPSHOT_YEAR     = 2017           # (không dùng nếu bạn giữ rule 14–68)\n",
    "\n",
    "# ========= 1) Field Format =========\n",
    "dfm = (\n",
    "    df_members\n",
    "      .withColumn(\"msno\", F.lower(F.trim(F.col(\"msno\"))))\n",
    "      .withColumn(\"city\", F.col(\"city\").cast(\"int\"))\n",
    "      .withColumn(\"bd\", F.col(\"bd\").cast(\"int\"))\n",
    "      .withColumn(\"gender\", F.lower(F.trim(F.col(\"gender\"))))\n",
    "      .withColumn(\"registered_via\", F.col(\"registered_via\").cast(\"int\"))\n",
    "      .withColumn(\"registration_init_time\", F.col(\"registration_init_time\").cast(\"string\"))\n",
    ")\n",
    "\n",
    "# ========= 2) Date =========\n",
    "dfm = dfm.withColumn(\n",
    "    \"registration_date\",\n",
    "    F.to_date(F.col(\"registration_init_time\"), \"yyyyMMdd\")\n",
    ")\n",
    "\n",
    "# ========= 3) City clean =========\n",
    "dfm = dfm.withColumn(\n",
    "    \"city_clean\",\n",
    "    F.when(F.col(\"city\") <= 0, None).otherwise(F.col(\"city\"))\n",
    ")\n",
    "\n",
    "# ========= 4.1) Gender clean =========\n",
    "dfm = dfm.withColumn(\n",
    "    \"gender_norm\",\n",
    "    F.when(F.col(\"gender\").isin(\"male\", \"female\"), F.col(\"gender\")).otherwise(F.lit(\"unknown\"))\n",
    ")\n",
    "\n",
    "# ========= 4.2) Gender one-hot =========\n",
    "dfm = (dfm\n",
    "    .drop(\"gender_male\",\"gender_female\",\"gender_unknown\")\n",
    "    .withColumn(\"gender_male\",    (F.col(\"gender_norm\")==\"male\").cast(\"int\"))\n",
    "    .withColumn(\"gender_female\",  (F.col(\"gender_norm\")==\"female\").cast(\"int\"))\n",
    "    .withColumn(\"gender_unknown\", (F.col(\"gender_norm\")==\"unknown\").cast(\"int\"))\n",
    ")\n",
    "\n",
    "# ========= 5) BD clean rule: 14–68 & count >= 1000 =========\n",
    "bd_hist = dfm.groupBy(\"bd\").agg(F.count(\"*\").alias(\"bd_count\"))\n",
    "dfm = (\n",
    "    dfm.join(bd_hist, on=\"bd\", how=\"left\")\n",
    "       .withColumn(\"bd_count\", F.coalesce(F.col(\"bd_count\"), F.lit(0)))\n",
    "       .withColumn(\n",
    "           \"bd_clean\",\n",
    "           F.when((F.col(\"bd\").between(14, 68)) & (F.col(\"bd_count\") >= 1000), F.col(\"bd\"))\n",
    "            .otherwise(F.lit(None).cast(\"int\"))\n",
    "       )\n",
    "       .drop(\"bd_count\")\n",
    ")\n",
    "\n",
    "\n",
    "# ========= 6) Tenure to cutoff =========\n",
    "dfm = dfm.withColumn(\n",
    "    \"tenure_days_at_snapshot\",\n",
    "    F.datediff(F.to_date(F.lit(SNAPSHOT_DATE_STR)), F.col(\"registration_date\"))\n",
    ")\n",
    "\n",
    "# ========= 7) Frequency enrich (Silver+) =========\n",
    "# 7a) registered_via frequency\n",
    "total_cnt = dfm.count()  # nếu bảng rất lớn, có thể approx bằng sample ratio\n",
    "via_freq = (\n",
    "    dfm.groupBy(\"registered_via\")\n",
    "       .agg((F.count(\"*\") / F.lit(total_cnt)).alias(\"registered_via_freq\"))\n",
    ")\n",
    "\n",
    "# 7b) city frequency\n",
    "city_freq = (\n",
    "    dfm.groupBy(\"city_clean\")\n",
    "       .agg((F.count(\"*\") / F.lit(total_cnt)).alias(\"city_freq\"))\n",
    ")\n",
    "\n",
    "# 7c) Join freq\n",
    "dfm = (\n",
    "    dfm.drop(\"registered_via_freq\", \"city_freq\")\n",
    "       .join(via_freq, on=\"registered_via\", how=\"left\")\n",
    "       .join(city_freq, on=\"city_clean\",  how=\"left\")\n",
    "       .fillna({\"registered_via_freq\": 0.0, \"city_freq\": 0.0})\n",
    ")\n",
    "\n",
    "# ========= 8) SILVER (clean + enrich) =========\n",
    "silver_cols = [\n",
    "    \"msno\",\n",
    "    \"city_clean\",\n",
    "    \"bd_clean\",\n",
    "    \"gender_norm\", \"gender_male\",\"gender_female\",\"gender_unknown\",\n",
    "    \"registered_via\",\n",
    "    \"registration_date\",\n",
    "    \"tenure_days_at_snapshot\",\n",
    "    \"registered_via_freq\",\n",
    "    \"city_freq\"\n",
    "]\n",
    "silver_members = dfm.select(*silver_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a551931-8c6e-40d1-8858-71c600199f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Layer 2 -------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dc48c12-6a8f-4b5b-96f5-a758c7b42126",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "cols_to_drop = [c for c in [\n",
    "    \"bd\", \"bd_clean\",\n",
    "    \"gender\", \"gender_norm\",\n",
    "    \"gender_male\", \"gender_female\",\n",
    "    \"gender_unknown\", \"gender_unknown_flag\"\n",
    "] if c in silver_members.columns]\n",
    "\n",
    "df2 = silver_members.drop(*cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1701b46c-5adf-4f7f-a03b-cdde6fb1b452",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.withColumn(\"city_clean\", F.col(\"city_clean\").cast(\"string\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0ceeb3a-102e-468b-b0a6-bfdbd1bb122e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"registered_via\" in df2.columns:\n",
    "    df2 = df2.withColumn(\"registered_via\", F.col(\"registered_via\").cast(\"string\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d849405a-6ef0-4a15-9798-e358b7b78320",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "pipe_silver = Pipeline(stages=[\n",
    "    StringIndexer(inputCol=\"city_clean\",      outputCol=\"city_idx\", handleInvalid=\"keep\"),\n",
    "    StringIndexer(inputCol=\"registered_via\",  outputCol=\"via_idx\",  handleInvalid=\"keep\"),\n",
    "    OneHotEncoder(inputCols=[\"city_idx\",\"via_idx\"], outputCols=[\"city_oh\",\"via_oh\"], dropLast=True)\n",
    "])\n",
    "\n",
    "sil_model = pipe_silver.fit(df2)\n",
    "df_silver = (sil_model.transform(df2)\n",
    "             .select(*df2.columns, \"city_idx\",\"via_idx\",\"city_oh\",\"via_oh\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6bc01bb-c4ca-4b36-9dbc-6b4387ca504b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- msno: string (nullable = true)\n",
      " |-- city_clean: string (nullable = true)\n",
      " |-- registered_via: string (nullable = true)\n",
      " |-- registration_date: date (nullable = true)\n",
      " |-- tenure_days_at_snapshot: integer (nullable = true)\n",
      " |-- registered_via_freq: double (nullable = false)\n",
      " |-- city_freq: double (nullable = false)\n",
      " |-- city_idx: double (nullable = false)\n",
      " |-- via_idx: double (nullable = false)\n",
      " |-- city_oh: vector (nullable = true)\n",
      " |-- via_oh: vector (nullable = true)\n",
      "\n",
      "+-------+-----------+----------+\n",
      "| n_rows|n_city_null|n_via_null|\n",
      "+-------+-----------+----------+\n",
      "|6769473|          0|         0|\n",
      "+-------+-----------+----------+\n",
      "\n",
      "+----------+--------+--------------+--------------+-------+--------------+\n",
      "|city_clean|city_idx|city_oh       |registered_via|via_idx|via_oh        |\n",
      "+----------+--------+--------------+--------------+-------+--------------+\n",
      "|14        |7.0     |(21,[7],[1.0])|9             |2.0    |(18,[2],[1.0])|\n",
      "|13        |2.0     |(21,[2],[1.0])|9             |2.0    |(18,[2],[1.0])|\n",
      "|6         |6.0     |(21,[6],[1.0])|9             |2.0    |(18,[2],[1.0])|\n",
      "|13        |2.0     |(21,[2],[1.0])|9             |2.0    |(18,[2],[1.0])|\n",
      "|15        |5.0     |(21,[5],[1.0])|9             |2.0    |(18,[2],[1.0])|\n",
      "+----------+--------+--------------+--------------+-------+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------+----------+--------------+-----------------+-----------------------+--------------------+------------------+--------+-------+--------------+---------------+\n",
      "|msno                                        |city_clean|registered_via|registration_date|tenure_days_at_snapshot|registered_via_freq |city_freq         |city_idx|via_idx|city_oh       |via_oh         |\n",
      "+--------------------------------------------+----------+--------------+-----------------+-----------------------+--------------------+------------------+--------+-------+--------------+---------------+\n",
      "|grugjyjs++wxah75n0kcpxr4qf9hb9mv0hbm1wkzfji=|1         |1             |2016-06-08       |265                    |6.352045425101776E-6|0.7097045811394772|0.0     |14.0   |(21,[0],[1.0])|(18,[14],[1.0])|\n",
      "|yxl0onnyqtkz3aio+e+3hqjia3kvyglhes9+pfpsspg=|1         |1             |2016-07-26       |217                    |6.352045425101776E-6|0.7097045811394772|0.0     |14.0   |(21,[0],[1.0])|(18,[14],[1.0])|\n",
      "|jnw5itaephaofmnkxbceurgp22jqdcchskgn3at8uzo=|1         |1             |2016-09-28       |153                    |6.352045425101776E-6|0.7097045811394772|0.0     |14.0   |(21,[0],[1.0])|(18,[14],[1.0])|\n",
      "|hy7hzet8vdxgjsxyeef9jdeuoggtbcu24cmk0o6q5ki=|1         |1             |2016-06-17       |256                    |6.352045425101776E-6|0.7097045811394772|0.0     |14.0   |(21,[0],[1.0])|(18,[14],[1.0])|\n",
      "|xlr5ekrdolykn3tusa2ptfpo8tcbeqwt1cltoj+8+qa=|1         |13            |2016-11-12       |108                    |8.05823437068144E-4 |0.7097045811394772|0.0     |5.0    |(21,[0],[1.0])|(18,[5],[1.0]) |\n",
      "|yohkfwts0bhbixxzo/ji46rspscai2rjrvjuwnfeh0u=|1         |13            |2016-11-22       |98                     |8.05823437068144E-4 |0.7097045811394772|0.0     |5.0    |(21,[0],[1.0])|(18,[5],[1.0]) |\n",
      "|zi7a3yqd/5sj/wrenhrxjyfiwsejyelo9fkglc/koq4=|1         |13            |2017-03-11       |-11                    |8.05823437068144E-4 |0.7097045811394772|0.0     |5.0    |(21,[0],[1.0])|(18,[5],[1.0]) |\n",
      "|f+g5iw4+w7up0iuyxlbviyk2kt8obtjupllflnvnzew=|1         |13            |2017-03-14       |-14                    |8.05823437068144E-4 |0.7097045811394772|0.0     |5.0    |(21,[0],[1.0])|(18,[5],[1.0]) |\n",
      "|iintxhevulupexwb2mhzwsfruic8q/kd5e0hxme/prw=|1         |13            |2016-12-03       |87                     |8.05823437068144E-4 |0.7097045811394772|0.0     |5.0    |(21,[0],[1.0])|(18,[5],[1.0]) |\n",
      "|jpojjiyjrsek3svtc3kzsyddoyzbqox/hwla/+0ai20=|1         |13            |2016-12-04       |86                     |8.05823437068144E-4 |0.7097045811394772|0.0     |5.0    |(21,[0],[1.0])|(18,[5],[1.0]) |\n",
      "+--------------------------------------------+----------+--------------+-----------------+-----------------------+--------------------+------------------+--------+-------+--------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_silver.printSchema()\n",
    "df_silver.selectExpr(\n",
    "    \"count(*) as n_rows\",\n",
    "    \"sum(case when city_clean is null then 1 else 0 end) as n_city_null\",\n",
    "    \"sum(case when registered_via is null then 1 else 0 end) as n_via_null\"\n",
    ").show()\n",
    "\n",
    "df_silver.select(\"city_clean\",\"city_idx\",\"city_oh\",\n",
    "                 \"registered_via\",\"via_idx\",\"via_oh\").limit(5).show(truncate=False)\n",
    "\n",
    "df_silver.limit(10).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93ed8df2-b305-4ee1-a2d2-85294e278913",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Silver layer saved to datamart/silver/members\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "output_path = \"datamart/silver/members\"\n",
    "\n",
    "(\n",
    "    df_silver\n",
    "      .coalesce(10)             # tùy: giảm số file output, nếu local có thể coalesce(10)\n",
    "      .write\n",
    "      .mode(\"overwrite\")         # ghi đè nếu có\n",
    "      .option(\"compression\", \"snappy\")\n",
    "      .parquet(output_path)\n",
    ")\n",
    "\n",
    "print(f\"✅ Silver layer saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1264c7e1-d5a1-4f0e-a996-978588cd63d0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3e714473-bf0b-4702-bf05-ddd60ceee877",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = (spark.read\n",
    "      .option(\"header\", True)\n",
    "      .option(\"inferSchema\", True)\n",
    "      .csv(\"data/train.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "11cf6904-d634-4c63-931f-cc3400b7a0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|                msno|is_churn|\n",
      "+--------------------+--------+\n",
      "|waLDQMmcOu2jLDaV1...|       1|\n",
      "|QA7uiXy8vIbUSPOkC...|       1|\n",
      "|fGwBva6hikQmTJzrb...|       1|\n",
      "|mT5V8rEpa+8wuqi6x...|       1|\n",
      "|XaPhtGLk/5UvvOYHc...|       1|\n",
      "|GBy8qSz16X5iYWD+3...|       1|\n",
      "|lYLh7TdkWpIoQs3i3...|       1|\n",
      "|T0FF6lumjKcqEO0O+...|       1|\n",
      "|Nb1ZGEmagQeba5E+n...|       1|\n",
      "|MkuWz0Nq6/Oq5fKqR...|       1|\n",
      "|I8dFN2EjFN1mt4Xel...|       1|\n",
      "|0Ip2rzeoa44alqEw3...|       1|\n",
      "|piVhWxrWDmiNQFY6x...|       1|\n",
      "|wEUOkYvyz3xTOx2p9...|       1|\n",
      "|xt4EjWRyXBMgEgKBJ...|       1|\n",
      "|QS3ob4zLlWcWzBIlb...|       1|\n",
      "|9iW/UpqRoviya9CQh...|       1|\n",
      "|d7QVMhAzjj4yc1Ojj...|       1|\n",
      "|uV7rJjHPrpNssDMmY...|       1|\n",
      "|TZxhkfZ9NwxqnUrNs...|       1|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3ca70938-0fef-49a0-9b1e-734a721b6f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "992931"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7c67f434-5ebc-435c-b182-55e6c68022ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df_train_v2 = (spark.read\n",
    "      .option(\"header\", True)\n",
    "      .option(\"inferSchema\", True)\n",
    "      .csv(\"data/train_v2.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b6f55ece-5fe1-47b5-ada6-7eab484014b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "970960"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_v2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5249016b-b11f-4c40-baa3-5f10152b6f19",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_members' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdf_members\u001b[49m.head()\n",
      "\u001b[31mNameError\u001b[39m: name 'df_members' is not defined"
     ]
    }
   ],
   "source": [
    "df_members.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51668a49-4d44-4501-9ba3-6d20b25cafee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_v2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9a81ded-bdfa-4ab0-b985-5398553505fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train_v2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdf_train_v2\u001b[49m.show(\u001b[32m5\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'df_train_v2' is not defined"
     ]
    }
   ],
   "source": [
    "df_train_v2.show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
