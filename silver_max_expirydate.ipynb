{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0a092768-e48e-451e-b4df-26e2e69c8269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pprint\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "from pyspark.sql.functions import to_date, col\n",
    "from pyspark.sql.types import StringType, IntegerType, FloatType, DateType\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "from pyspark.sql.functions import col, year, month, dayofmonth, to_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "551f2e7d-2f14-4726-89c4-dfe7d87d6e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SparkSession\n",
    "spark = pyspark.sql.SparkSession.builder \\\n",
    "    .appName(\"dev\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96578403-c503-4a44-b88c-0cd115f60218",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4f81b185-c3a0-413d-bd77-5efa2864513c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "silver_transactions_path = \"/app/datamart/silver/transactions\" \n",
    "silver_latest_transactions_path = \"/app/datamart/silver/latest_transactions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "827e02c0-1d2e-42a9-a290-9b7a8fe648d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silver Transactions schema:\n",
      "root\n",
      " |-- msno: string (nullable = true)\n",
      " |-- payment_method_id: integer (nullable = true)\n",
      " |-- payment_plan_days: integer (nullable = true)\n",
      " |-- plan_list_price: integer (nullable = true)\n",
      " |-- actual_amount_paid: integer (nullable = true)\n",
      " |-- is_auto_renew: integer (nullable = true)\n",
      " |-- transaction_date: date (nullable = true)\n",
      " |-- membership_expire_date: date (nullable = true)\n",
      " |-- is_cancel: integer (nullable = true)\n",
      " |-- source_file: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- transaction_id: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load all Silver parquet files\n",
    "df_silver = spark.read.parquet(silver_transactions_path)\n",
    "print(\"Silver Transactions schema:\")\n",
    "df_silver.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed3378a-f501-4e43-912f-f897cb7ab59f",
   "metadata": {},
   "source": [
    "# Select inference date as a placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "720d2d9c-061b-4143-9a52-56fd80dae96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today's date is set to: 2017-03-01\n"
     ]
    }
   ],
   "source": [
    "inference_date = \"2017-03-01\"\n",
    "print(f\"Today's date is set to: {inference_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a2057de1-c9cc-46fb-8f39-7ead47836c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter transactions table based on transaction_date <= inference date\n",
    "\n",
    "df_silver_filtered = (\n",
    "    df_silver\n",
    "    .filter(F.to_date(F.col(\"transaction_date\")) <= F.to_date(F.lit(inference_date)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b1e62dac-2fdd-4bf3-a563-ecaebb1b5afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Create a new column called 'Total plan days'\n",
    "df_silver_filtered = df_silver_filtered.withColumn(\n",
    "    \"total_plan_days\",\n",
    "    F.datediff(F.col(\"membership_expire_date\"), F.col(\"transaction_date\"))\n",
    ")\n",
    "\n",
    "# Partition by msno (member ID) and order by transaction_date\n",
    "\n",
    "window_spec = Window.partitionBy(\"msno\").orderBy(F.col(\"transaction_date\").desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "887933cf-2e14-4192-ae8e-d9a7ed4c3d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Get max transaction_date within each user\n",
    "\n",
    "df_silver_filtered = df_silver_filtered.withColumn(\n",
    "    \"max_transaction_date\",\n",
    "    F.max(\"transaction_date\").over(window_spec)\n",
    ")\n",
    "\n",
    "# 3) Filter rows that match the max transaction date (tied rows)\n",
    "df_tied_rows = df_silver_filtered.filter(F.col(\"transaction_date\") == F.col(\"max_transaction_date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "367a5544-6614-4da1-ad04-07dac9bff61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Custom Logic within Tied Rows ---\n",
    "\n",
    "# Define a window for ranking total_plan_days within the tied group\n",
    "tied_row_window_rank = Window.partitionBy(\"msno\").orderBy(F.col(\"total_plan_days\").desc())\n",
    "\n",
    "# Get the rank of total_plan_days within the tied group (1 is the max days)\n",
    "df_ranked = df_tied_rows.withColumn(\"plan_days_rank\", F.rank().over(tied_row_window_rank))\n",
    "\n",
    "# Identify if a cancellation exists in the tied group (flag per user)\n",
    "df_cancellation_exists = df_tied_rows.groupBy(\"msno\").agg(\n",
    "    F.max(F.col(\"is_cancel\")).alias(\"cancellation_in_group\")\n",
    ")\n",
    "\n",
    "df_final = df_ranked.join(df_cancellation_exists, on=\"msno\", how=\"left\").fillna({\"cancellation_in_group\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e0fae060-cd85-4c9a-89e7-ef072241ae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 & 5) Create the final selection metric (final_priority)\n",
    "# Logic: \n",
    "#   A. If a cancellation exists AND (this row is a cancellation AND this row has the 2nd max plan days) -> Priority 1\n",
    "#   B. OR (if no cancellation exists in the group AND this row has the max plan days (rank 1)) -> Priority 1\n",
    "df_final = df_final.withColumn(\n",
    "    \"final_priority\",\n",
    "    F.when(\n",
    "        # FIX 1: Explicitly check is_cancel == 1 for BOOLEAN comparison\n",
    "        (F.col(\"cancellation_in_group\") == 1) & \n",
    "        (F.col(\"is_cancel\") == 1) & \n",
    "        (F.col(\"plan_days_rank\") == 2), \n",
    "        1 \n",
    "    ).when(\n",
    "        # FIX 2: Explicitly check cancellation_in_group == 0 for BOOLEAN comparison\n",
    "        (F.col(\"cancellation_in_group\") == 0) & \n",
    "        (F.col(\"plan_days_rank\") == 1), \n",
    "        1 \n",
    "    ).when(\n",
    "        # FIX 3: Explicitly check is_cancel != 1 for BOOLEAN comparison\n",
    "        (F.col(\"cancellation_in_group\") == 1) & \n",
    "        (F.col(\"plan_days_rank\") == 1) &\n",
    "        (F.col(\"is_cancel\") != 1), # <-- FIXED\n",
    "        1 \n",
    "    ).when(\n",
    "        # FIX 4: Explicitly check cancellation_in_group == 0 for BOOLEAN comparison\n",
    "        (F.col(\"cancellation_in_group\") == 0) & \n",
    "        (F.col(\"plan_days_rank\") == 1), \n",
    "        1 \n",
    "    ).otherwise(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "693e5764-6c6a-4868-8c32-701c28b5df82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the logic above is complex, we use a simpler explicit sort order to guarantee the result:\n",
    "df_latest_transaction_final = df_tied_rows.withColumn(\n",
    "    \"custom_rank\",\n",
    "    F.row_number().over(\n",
    "        Window.partitionBy(\"msno\").orderBy(\n",
    "            # Priority 1: Check for cancellation at 2nd max plan days (encoded by custom metric)\n",
    "            F.when((F.col(\"is_cancel\") == 1) & (F.rank().over(tied_row_window_rank) == 2), 1).otherwise(0).desc(),\n",
    "            # Priority 2: Max plan days (desc) (for standard fallback)\n",
    "            F.col(\"Total_plan_days\").desc(),\n",
    "            # Priority 3: Tie-breaker (transaction_date desc)\n",
    "            F.col(\"transaction_date\").desc()\n",
    "        )\n",
    "    )\n",
    ").filter(F.col(\"custom_rank\") == 1).drop(\"custom_rank\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d7008c6e-a646-4746-8de8-38ac276c5ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+---------------+---------+\n",
      "|                msno|transaction_date|Total_plan_days|is_cancel|\n",
      "+--------------------+----------------+---------------+---------+\n",
      "|++0GCV3WGMjibrwCn...|      2016-11-25|              7|        0|\n",
      "|++3hfQtTKeHLVuBHI...|      2016-02-15|              0|        1|\n",
      "|++4RuqBw0Ss6bQU4o...|      2017-02-13|             28|        0|\n",
      "|++5Z7z4xXBhCjID+B...|      2017-02-23|             28|        0|\n",
      "|++6P09mCSJSh+Ft2p...|      2017-02-28|             44|        0|\n",
      "+--------------------+----------------+---------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Example of showing the final DataFrame\n",
    "df_latest_transaction_final.select(\"msno\", \"transaction_date\", \"Total_plan_days\", \"is_cancel\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c9671e26-e83d-4f49-b407-7f9d05e68254",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Silver layer (Latest_transactions) successfully written to: /app/datamart/silver/latest_transactions\n"
     ]
    }
   ],
   "source": [
    "# Save to silver layer\n",
    "\n",
    "# Save as Parquet, without partitioning\n",
    "(\n",
    "    df_latest_transaction_final\n",
    "    .write\n",
    "    .mode(\"overwrite\")\n",
    "    .parquet(silver_latest_transactions_path)\n",
    ")\n",
    "\n",
    "print(f\"✅ Silver layer (Latest_transactions) successfully written to: {silver_latest_transactions_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5583c6b-607e-4ff6-b7c0-b9c6659cdb08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
